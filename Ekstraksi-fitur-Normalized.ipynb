{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:19:47.451945Z",
     "iopub.status.busy": "2025-12-09T19:19:47.451699Z",
     "iopub.status.idle": "2025-12-09T19:20:33.633545Z",
     "shell.execute_reply": "2025-12-09T19:20:33.632750Z",
     "shell.execute_reply.started": "2025-12-09T19:19:47.451925Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "PROGRAM EKSTRAKSI FITUR MATA (RESNET50)\n",
      "==================================================\n",
      "Mencari data di: /kaggle/input/eye-diseases-classification/dataset\n",
      "   Ditemukan folder 'normal': 1074 gambar\n",
      "   Ditemukan folder 'cataract': 1038 gambar\n",
      "   Ditemukan folder 'glaucoma': 1007 gambar\n",
      "   Ditemukan folder 'diabetic_retinopathy': 1098 gambar\n",
      "\n",
      "Menggunakan device: cuda\n",
      "Loading ResNet50 pretrained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 172MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mulai ekstraksi fitur dari 4217 gambar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Proses Ekstraksi: 100%|██████████| 132/132 [00:33<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menyimpan ke CSV di /kaggle/working/...\n",
      "Sukses! File tersimpan di: /kaggle/working/resnet50_features(normalized).csv\n",
      "\n",
      "Selesai! Silakan cek tab 'Output' di Kaggle untuk mendownload CSV-nya.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Supaya output bersih\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== KONFIGURASI PATH KAGGLE ====================\n",
    "# Sesuai dengan nama dataset di screenshot kamu: 'eye-dataset'\n",
    "DATA_DIR = '/kaggle/input/eye-diseases-classification/dataset' \n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Kategori penyakit (Pastikan nama folder di dalam dataset sama persis dengan ini)\n",
    "CATEGORIES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']\n",
    "\n",
    "# ==================== 1. DATASET CLASS ====================\n",
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, img_path\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    \"\"\"Load semua gambar dan label dari direktori Kaggle\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Mencari data di: {data_dir}\")\n",
    "    \n",
    "    # Cek apakah folder utama ada\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Folder {data_dir} tidak ditemukan!\")\n",
    "        print(\"Coba cek 'Copy File Path' di sidebar kanan Kaggle.\")\n",
    "        return [], []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        \n",
    "        # Cek apakah folder kategori (misal /cataract) ada\n",
    "        if os.path.exists(category_path):\n",
    "            files = os.listdir(category_path)\n",
    "            print(f\"   Ditemukan folder '{category}': {len(files)} gambar\")\n",
    "            \n",
    "            for img_name in files:\n",
    "                img_path = os.path.join(category_path, img_name)\n",
    "                # Ambil hanya file gambar\n",
    "                if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(category)\n",
    "        else:\n",
    "            print(f\"   Warning: Folder kategori '{category}' tidak ditemukan di {category_path}\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# ==================== 2. PROSES EKSTRAKSI (RESNET50) ====================\n",
    "def extract_features_resnet(image_paths, labels, batch_size=32):\n",
    "    \n",
    "    # Cek Device (Gunakan GPU P100/T4 di Kaggle agar cepat)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nMenggunakan device: {device}\")\n",
    "    \n",
    "    if str(device) == 'cpu':\n",
    "        print(\"Warning: Kamu sedang menggunakan CPU. Aktifkan GPU Accelerator di Settings Kaggle agar lebih cepat!\")\n",
    "    \n",
    "    # Load Model\n",
    "    print(\"Loading ResNet50 pretrained model...\")\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet = nn.Sequential(*list(resnet.children())[:-1]) # Buang head\n",
    "    resnet = resnet.to(device)\n",
    "    resnet.eval()\n",
    "    \n",
    "    # Preprocessing standar ImageNet\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Encode label text ke angka\n",
    "    label_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n",
    "    encoded_labels = [label_to_idx[label] for label in labels]\n",
    "    \n",
    "    dataset = EyeDataset(image_paths, encoded_labels, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    paths_list = []\n",
    "    \n",
    "    print(f\"Mulai ekstraksi fitur dari {len(image_paths)} gambar...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch, paths_batch in tqdm(dataloader, desc=\"Proses Ekstraksi\"):\n",
    "            images = images.to(device)\n",
    "            output = resnet(images)\n",
    "            output = output.view(output.size(0), -1)\n",
    "            \n",
    "            features_list.append(output.cpu().numpy())\n",
    "            labels_list.append(labels_batch.numpy())\n",
    "            paths_list.extend(paths_batch)\n",
    "    \n",
    "    return np.vstack(features_list), np.hstack(labels_list), paths_list\n",
    "\n",
    "# ==================== 3. SIMPAN CSV ====================\n",
    "def save_to_csv(features, labels, paths):\n",
    "    print(\"\\nMenyimpan ke CSV di /kaggle/working/...\")\n",
    "    \n",
    "    feature_cols = [f'feature_{i}' for i in range(features.shape[1])]\n",
    "    df = pd.DataFrame(features, columns=feature_cols)\n",
    "    \n",
    "    df.insert(0, 'image_path', paths)\n",
    "    df.insert(0, 'label_encoded', labels)\n",
    "    df.insert(0, 'label', [CATEGORIES[label] for label in labels])\n",
    "    \n",
    "    # Simpan di working directory Kaggle\n",
    "    output_filename = '/kaggle/working/resnet50_features(normalized).csv'\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f\"Sukses! File tersimpan di: {output_filename}\")\n",
    "    return df\n",
    "\n",
    "# ==================== MAIN ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*50)\n",
    "    print(\"PROGRAM EKSTRAKSI FITUR MATA (RESNET50)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    image_paths, labels = load_dataset(DATA_DIR)\n",
    "    \n",
    "    if len(image_paths) > 0:\n",
    "        # 2. Ekstraksi\n",
    "        features, encoded_labels, paths = extract_features_resnet(image_paths, labels, BATCH_SIZE)\n",
    "        \n",
    "        # 3. Simpan\n",
    "        save_to_csv(features, encoded_labels, paths)\n",
    "        \n",
    "        print(\"\\nSelesai! Silakan cek tab 'Output' di Kaggle untuk mendownload CSV-nya.\")\n",
    "    else:\n",
    "        print(\"\\nTidak ada gambar yang diproses. Cek path dataset kamu lagi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T19:21:46.693559Z",
     "iopub.status.busy": "2025-12-09T19:21:46.693253Z",
     "iopub.status.idle": "2025-12-09T19:22:22.857837Z",
     "shell.execute_reply": "2025-12-09T19:22:22.856934Z",
     "shell.execute_reply.started": "2025-12-09T19:21:46.693536Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "EFFICIENTNET-B3 FEATURE EXTRACTION (SIMPLE)\n",
      "==================================================\n",
      "Membaca dataset dari: /kaggle/input/eye-diseases-classification/dataset\n",
      "   normal: 1074 gambar\n",
      "   cataract: 1038 gambar\n",
      "   glaucoma: 1007 gambar\n",
      "   diabetic_retinopathy: 1098 gambar\n",
      "\n",
      "Menggunakan Device: cuda\n",
      "Loading EfficientNet-B3 (Pretrained)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b3_rwightman-b3899882.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b3_rwightman-b3899882.pth\n",
      "100%|██████████| 47.2M/47.2M [00:00<00:00, 193MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mulai Ekstraksi Fitur (4217 gambar)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:29<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menyimpan ke CSV...\n",
      "Selesai! File tersimpan: efficientnet_features(normalized).csv\n",
      "   Dimensi Data: (4217, 1539)\n",
      "\n",
      "Siap! Silakan download CSV dari tab 'Output'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Matikan warning agar output bersih\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== KONFIGURASI ====================\n",
    "DATA_DIR = '/kaggle/input/eye-diseases-classification/dataset'  # Sesuaikan path jika perlu\n",
    "\n",
    "# EfficientNet-B3 WAJIB menggunakan resolusi 300x300\n",
    "IMG_SIZE = 300  \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Urutan Kategori\n",
    "CATEGORIES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']\n",
    "\n",
    "# ==================== 1. DATASET CLASS ====================\n",
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label, img_path\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    \"\"\"Load path gambar dan labelnya\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    print(f\"Membaca dataset dari: {data_dir}\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"Error: Path dataset tidak ditemukan!\")\n",
    "        return [], []\n",
    "\n",
    "    for category in CATEGORIES:\n",
    "        category_path = os.path.join(data_dir, category)\n",
    "        if os.path.exists(category_path):\n",
    "            files = [f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            for img_name in files:\n",
    "                image_paths.append(os.path.join(category_path, img_name))\n",
    "                labels.append(category)\n",
    "            print(f\"   {category}: {len(files)} gambar\")\n",
    "        else:\n",
    "            print(f\"   Folder '{category}' tidak ditemukan.\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "# ==================== 2. PROSES EKSTRAKSI (EFFICIENTNET-B3) ====================\n",
    "def extract_features_efficientnet(image_paths, labels, batch_size=32):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nMenggunakan Device: {device}\")\n",
    "    \n",
    "    # 1. Load Model EfficientNet-B3\n",
    "    print(\"Loading EfficientNet-B3 (Pretrained)...\")\n",
    "    weights = models.EfficientNet_B3_Weights.DEFAULT\n",
    "    model = models.efficientnet_b3(weights=weights)\n",
    "    \n",
    "    # 2. Hapus Classifier (Ambil fiturnya saja)\n",
    "    model.classifier = nn.Identity()\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 3. Preprocessing (Resize ke 300x300)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 4. Buat DataLoader\n",
    "    label_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n",
    "    encoded_labels = [label_to_idx[label] for label in labels]\n",
    "    \n",
    "    dataset = EyeDataset(image_paths, encoded_labels, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # 5. Loop Ekstraksi\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    paths_list = []\n",
    "    \n",
    "    print(f\"\\nMulai Ekstraksi Fitur ({len(image_paths)} gambar)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels_batch, paths_batch in tqdm(dataloader):\n",
    "            images = images.to(device)\n",
    "            \n",
    "            output = model(images)\n",
    "            output = output.view(output.size(0), -1) # Flatten\n",
    "            \n",
    "            features_list.append(output.cpu().numpy())\n",
    "            labels_list.append(labels_batch.numpy())\n",
    "            paths_list.extend(paths_batch)\n",
    "    \n",
    "    # Gabungkan hasil\n",
    "    features = np.vstack(features_list)\n",
    "    all_labels = np.hstack(labels_list)\n",
    "    \n",
    "    return features, all_labels, paths_list\n",
    "\n",
    "# ==================== 3. OUTPUT CSV ====================\n",
    "def save_to_csv(features, labels, paths):\n",
    "    print(\"\\nMenyimpan ke CSV...\")\n",
    "    \n",
    "    # Buat nama kolom (feature_0 ... feature_1535)\n",
    "    cols = [f'feature_{i}' for i in range(features.shape[1])]\n",
    "    \n",
    "    df = pd.DataFrame(features, columns=cols)\n",
    "    \n",
    "    # Tambah info gambar di depan\n",
    "    df.insert(0, 'image_path', paths)\n",
    "    df.insert(0, 'label_encoded', labels)\n",
    "    df.insert(0, 'label', [CATEGORIES[l] for l in labels])\n",
    "    \n",
    "    # Simpan\n",
    "    filename = 'efficientnet_features(normalized).csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"Selesai! File tersimpan: {filename}\")\n",
    "    print(f\"   Dimensi Data: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# ==================== MAIN PROGRAM ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*50)\n",
    "    print(\"EFFICIENTNET-B3 FEATURE EXTRACTION (SIMPLE)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 1. Input\n",
    "    image_paths, labels = load_dataset(DATA_DIR)\n",
    "    \n",
    "    if len(image_paths) > 0:\n",
    "        # 2. Proses\n",
    "        features, encoded_labels, paths = extract_features_efficientnet(\n",
    "            image_paths, labels, BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        # 3. Output\n",
    "        save_to_csv(features, encoded_labels, paths)\n",
    "        \n",
    "        print(\"\\nSiap! Silakan download CSV dari tab 'Output'.\")\n",
    "    else:\n",
    "        print(\"\\nTidak ada gambar yang bisa diproses.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 4187300,
     "datasetId": 2440665,
     "isSourceIdPinned": false,
     "sourceId": 4130910,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
