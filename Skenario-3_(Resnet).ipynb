{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d1e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Matikan warning\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cek Library Boosting\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    xgb = None\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except ImportError:\n",
    "    lgb = None\n",
    "\n",
    "# Konfigurasi Global\n",
    "RANDOM_STATE = 42\n",
    "# List global untuk menampung hasil dari semua cell\n",
    "all_scenario_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2cb91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(scaled=False):\n",
    "    \"\"\"\n",
    "    Definisi Model (Sama seperti sebelumnya).\n",
    "    LogReg C=100 jika Scaled, C=1.0 jika Non-Scaled.\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    models['SVM'] = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    c_param = 100.0 if scaled else 1.0\n",
    "    models['Logistic Regression'] = LogisticRegression(C=c_param, max_iter=1000, random_state=RANDOM_STATE)\n",
    "    \n",
    "    models['Decision Tree'] = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    models['Random Forest'] = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "    \n",
    "    if xgb is not None:\n",
    "        models['XGBoost'] = xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "    if lgb is not None:\n",
    "        models['LightGBM'] = lgb.LGBMClassifier(random_state=RANDOM_STATE, verbose=-1)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, scenario_name, scaled_status):\n",
    "    models = get_models(scaled=scaled_status)\n",
    "    \n",
    "    print(f\"Running Skenario: {scenario_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        kategori = \"ENSEMBLE\" if name in ['Random Forest', 'XGBoost', 'LightGBM'] else \"SINGLE\"\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        all_scenario_results.append({\n",
    "            'Skenario': scenario_name,\n",
    "            'Category': kategori,\n",
    "            'Model': name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        print(f\"{name:<20} | F1: {f1:.2%}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af79f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tidak ditemukan: Dataset Split/train_resnet50_features(non normalized).csv\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI A (RESNET) =================\n",
    "# Input: Non-Normalized CSV\n",
    "# Proses: Tanpa Scaler\n",
    "train_path = 'Dataset Split/train_resnet50_features(non normalized).csv'\n",
    "test_path = 'Dataset Split/test_resnet50_features(non normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    evaluate_models(X_train, y_train, X_test, y_test, \n",
    "                   scenario_name=\"Non-Norm + No Scaler\", \n",
    "                   scaled_status=False)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca429d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tidak ditemukan: Dataset Split/train_resnet50_features(non normalized).csv\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI B (RESNET) =================\n",
    "# Input: Non-Normalized CSV\n",
    "# Proses: Dengan StandardScaler\n",
    "train_path = 'Dataset Split/train_resnet50_features(non normalized).csv'\n",
    "test_path = 'Dataset Split/test_resnet50_features(non normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Apply Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test, \n",
    "                   scenario_name=\"Non-Norm + With Scaler\", \n",
    "                   scaled_status=True)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd800cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tidak ditemukan: Dataset Split/train_resnet50_features(normalized).csv\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI C (RESNET) =================\n",
    "# Input: Normalized CSV\n",
    "# Proses: Tanpa Scaler\n",
    "train_path = 'Dataset Split/train_resnet50_features(normalized).csv'\n",
    "test_path = 'Dataset Split/test_resnet50_features(normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    evaluate_models(X_train, y_train, X_test, y_test, \n",
    "                   scenario_name=\"Normalized + No Scaler\", \n",
    "                   scaled_status=False)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055d93c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tidak ditemukan: Dataset Split/train_resnet50_features(normalized).csv\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI D (RESNET) =================\n",
    "# Input: Normalized CSV\n",
    "# Proses: Dengan StandardScaler\n",
    "train_path = 'Dataset Split/train_resnet50_features(normalized).csv'\n",
    "test_path = 'Dataset Split/test_resnet50_features(normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Apply Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test, \n",
    "                   scenario_name=\"Normalized + With Scaler\", \n",
    "                   scaled_status=True)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4432d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belum ada hasil yang dijalankan.\n"
     ]
    }
   ],
   "source": [
    "# ================= REKAPITULASI HASIL (RESNET50) =================\n",
    "if all_scenario_results:\n",
    "    df_final = pd.DataFrame(all_scenario_results)\n",
    "    \n",
    "    # Urutkan berdasarkan F1-Score Tertinggi\n",
    "    df_final = df_final.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"HASIL AKHIR: PERBANDINGAN KOMBINASI PREPROCESSING (RESNET50)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Format Tampilan Persen\n",
    "    output_table = df_final.copy()\n",
    "    for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
    "        output_table[col] = output_table[col].map('{:.2%}'.format)\n",
    "    \n",
    "    print(output_table.to_string(index=False))\n",
    "    \n",
    "    # Best Combination Logic\n",
    "    best = df_final.iloc[0]\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"BEST COMBINATION: {best['Skenario']}\")\n",
    "    print(f\"MODEL           : {best['Model']} ({best['Category']})\")\n",
    "    print(f\"F1-SCORE        : {best['F1-Score']:.2%}\")\n",
    "    print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Belum ada hasil yang dijalankan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
