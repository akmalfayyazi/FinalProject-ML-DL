{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4130910,"sourceType":"datasetVersion","datasetId":2440665,"isSourceIdPinned":false}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nimport warnings\n\n# Supaya output bersih\nwarnings.filterwarnings('ignore')\n\n# ==================== KONFIGURASI PATH KAGGLE ====================\n# Sesuai dengan nama dataset di screenshot kamu: 'eye-dataset'\nDATA_DIR = '/kaggle/input/eye-diseases-classification/dataset' \nIMG_SIZE = 224\nBATCH_SIZE = 32\n\n# Kategori penyakit (Pastikan nama folder di dalam dataset sama persis dengan ini)\nCATEGORIES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']\n\n# ==================== 1. DATASET CLASS ====================\nclass EyeDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label, img_path\n\ndef load_dataset(data_dir):\n    \"\"\"Load semua gambar dan label dari direktori Kaggle\"\"\"\n    image_paths = []\n    labels = []\n    \n    print(f\"Mencari data di: {data_dir}\")\n    \n    # Cek apakah folder utama ada\n    if not os.path.exists(data_dir):\n        print(f\"âŒ Error: Folder {data_dir} tidak ditemukan!\")\n        print(\"Coba cek 'Copy File Path' di sidebar kanan Kaggle.\")\n        return [], []\n\n    for category in CATEGORIES:\n        category_path = os.path.join(data_dir, category)\n        \n        # Cek apakah folder kategori (misal /cataract) ada\n        if os.path.exists(category_path):\n            files = os.listdir(category_path)\n            print(f\"   ğŸ“‚ Ditemukan folder '{category}': {len(files)} gambar\")\n            \n            for img_name in files:\n                img_path = os.path.join(category_path, img_name)\n                # Ambil hanya file gambar\n                if img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_paths.append(img_path)\n                    labels.append(category)\n        else:\n            print(f\"   âš ï¸ Warning: Folder kategori '{category}' tidak ditemukan di {category_path}\")\n    \n    return image_paths, labels\n\n# ==================== 2. PROSES EKSTRAKSI (RESNET50) ====================\ndef extract_features_resnet(image_paths, labels, batch_size=32):\n    \n    # Cek Device (Gunakan GPU P100/T4 di Kaggle agar cepat)\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nâœ… Menggunakan device: {device}\")\n    \n    if str(device) == 'cpu':\n        print(\"âš ï¸ Warning: Kamu sedang menggunakan CPU. Aktifkan GPU Accelerator di Settings Kaggle agar lebih cepat!\")\n    \n    # Load Model\n    print(\"Loading ResNet50 pretrained model...\")\n    resnet = models.resnet50(pretrained=True)\n    resnet = nn.Sequential(*list(resnet.children())[:-1]) # Buang head\n    resnet = resnet.to(device)\n    resnet.eval()\n    \n    # Preprocessing standar ImageNet\n    transform = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor()\n    ])\n    \n    # Encode label text ke angka\n    label_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n    encoded_labels = [label_to_idx[label] for label in labels]\n    \n    dataset = EyeDataset(image_paths, encoded_labels, transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    features_list = []\n    labels_list = []\n    paths_list = []\n    \n    print(f\"Mulai ekstraksi fitur dari {len(image_paths)} gambar...\")\n    \n    with torch.no_grad():\n        for images, labels_batch, paths_batch in tqdm(dataloader, desc=\"Proses Ekstraksi\"):\n            images = images.to(device)\n            output = resnet(images)\n            output = output.view(output.size(0), -1)\n            \n            features_list.append(output.cpu().numpy())\n            labels_list.append(labels_batch.numpy())\n            paths_list.extend(paths_batch)\n    \n    return np.vstack(features_list), np.hstack(labels_list), paths_list\n\n# ==================== 3. SIMPAN CSV ====================\ndef save_to_csv(features, labels, paths):\n    print(\"\\nMenyimpan ke CSV di /kaggle/working/...\")\n    \n    feature_cols = [f'feature_{i}' for i in range(features.shape[1])]\n    df = pd.DataFrame(features, columns=feature_cols)\n    \n    df.insert(0, 'image_path', paths)\n    df.insert(0, 'label_encoded', labels)\n    df.insert(0, 'label', [CATEGORIES[label] for label in labels])\n    \n    # Simpan di working directory Kaggle\n    output_filename = '/kaggle/working/resnet50_features(non normalized).csv'\n    df.to_csv(output_filename, index=False)\n    \n    print(f\"âœ… Sukses! File tersimpan di: {output_filename}\")\n    return df\n\n# ==================== MAIN ====================\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"PROGRAM EKSTRAKSI FITUR MATA (RESNET50)\")\n    print(\"=\"*50)\n    \n    # 1. Load Data\n    image_paths, labels = load_dataset(DATA_DIR)\n    \n    if len(image_paths) > 0:\n        # 2. Ekstraksi\n        features, encoded_labels, paths = extract_features_resnet(image_paths, labels, BATCH_SIZE)\n        \n        # 3. Simpan\n        save_to_csv(features, encoded_labels, paths)\n        \n        print(\"\\nSelesai! Silakan cek tab 'Output' di Kaggle untuk mendownload CSV-nya.\")\n    else:\n        print(\"\\nâŒ Tidak ada gambar yang diproses. Cek path dataset kamu lagi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:07:41.369169Z","iopub.execute_input":"2025-12-07T15:07:41.369432Z","iopub.status.idle":"2025-12-07T15:08:22.328625Z","shell.execute_reply.started":"2025-12-07T15:07:41.369408Z","shell.execute_reply":"2025-12-07T15:08:22.327671Z"}},"outputs":[{"name":"stdout","text":"==================================================\nPROGRAM EKSTRAKSI FITUR MATA (RESNET50)\n==================================================\nMencari data di: /kaggle/input/eye-diseases-classification/dataset\n   ğŸ“‚ Ditemukan folder 'normal': 1074 gambar\n   ğŸ“‚ Ditemukan folder 'cataract': 1038 gambar\n   ğŸ“‚ Ditemukan folder 'glaucoma': 1007 gambar\n   ğŸ“‚ Ditemukan folder 'diabetic_retinopathy': 1098 gambar\n\nâœ… Menggunakan device: cuda\nLoading ResNet50 pretrained model...\nMulai ekstraksi fitur dari 4217 gambar...\n","output_type":"stream"},{"name":"stderr","text":"Proses Ekstraksi: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:32<00:00,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nMenyimpan ke CSV di /kaggle/working/...\nâœ… Sukses! File tersimpan di: /kaggle/working/resnet50_features(non normalized).csv\n\nSelesai! Silakan cek tab 'Output' di Kaggle untuk mendownload CSV-nya.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm\nimport warnings\n\n# Matikan warning agar output bersih\nwarnings.filterwarnings('ignore')\n\n# ==================== KONFIGURASI ====================\nDATA_DIR = '/kaggle/input/eye-diseases-classification/dataset'  # Sesuaikan path jika perlu\n\n# EfficientNet-B3 WAJIB menggunakan resolusi 300x300\nIMG_SIZE = 300  \nBATCH_SIZE = 32\n\n# Urutan Kategori\nCATEGORIES = ['normal', 'cataract', 'glaucoma', 'diabetic_retinopathy']\n\n# ==================== 1. DATASET CLASS ====================\nclass EyeDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label, img_path\n\ndef load_dataset(data_dir):\n    \"\"\"Load path gambar dan labelnya\"\"\"\n    image_paths = []\n    labels = []\n    \n    print(f\"ğŸ“‚ Membaca dataset dari: {data_dir}\")\n    if not os.path.exists(data_dir):\n        print(\"âŒ Error: Path dataset tidak ditemukan!\")\n        return [], []\n\n    for category in CATEGORIES:\n        category_path = os.path.join(data_dir, category)\n        if os.path.exists(category_path):\n            files = [f for f in os.listdir(category_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            for img_name in files:\n                image_paths.append(os.path.join(category_path, img_name))\n                labels.append(category)\n            print(f\"   âœ… {category}: {len(files)} gambar\")\n        else:\n            print(f\"   âš ï¸ Folder '{category}' tidak ditemukan.\")\n    \n    return image_paths, labels\n\n# ==================== 2. PROSES EKSTRAKSI (EFFICIENTNET-B3) ====================\ndef extract_features_efficientnet(image_paths, labels, batch_size=32):\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"\\nâš™ï¸ Menggunakan Device: {device}\")\n    \n    # 1. Load Model EfficientNet-B3\n    print(\"ğŸš€ Loading EfficientNet-B3 (Pretrained)...\")\n    weights = models.EfficientNet_B3_Weights.DEFAULT\n    model = models.efficientnet_b3(weights=weights)\n    \n    # 2. Hapus Classifier (Ambil fiturnya saja)\n    model.classifier = nn.Identity()\n    model = model.to(device)\n    model.eval()\n    \n    # 3. Preprocessing (Resize ke 300x300)\n    transform = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor()\n    ])\n    \n    # 4. Buat DataLoader\n    label_to_idx = {cat: idx for idx, cat in enumerate(CATEGORIES)}\n    encoded_labels = [label_to_idx[label] for label in labels]\n    \n    dataset = EyeDataset(image_paths, encoded_labels, transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    # 5. Loop Ekstraksi\n    features_list = []\n    labels_list = []\n    paths_list = []\n    \n    print(f\"\\nâ³ Mulai Ekstraksi Fitur ({len(image_paths)} gambar)...\")\n    \n    with torch.no_grad():\n        for images, labels_batch, paths_batch in tqdm(dataloader):\n            images = images.to(device)\n            \n            output = model(images)\n            output = output.view(output.size(0), -1) # Flatten\n            \n            features_list.append(output.cpu().numpy())\n            labels_list.append(labels_batch.numpy())\n            paths_list.extend(paths_batch)\n    \n    # Gabungkan hasil\n    features = np.vstack(features_list)\n    all_labels = np.hstack(labels_list)\n    \n    return features, all_labels, paths_list\n\n# ==================== 3. OUTPUT CSV ====================\ndef save_to_csv(features, labels, paths):\n    print(\"\\nğŸ’¾ Menyimpan ke CSV...\")\n    \n    # Buat nama kolom (feature_0 ... feature_1535)\n    cols = [f'feature_{i}' for i in range(features.shape[1])]\n    \n    df = pd.DataFrame(features, columns=cols)\n    \n    # Tambah info gambar di depan\n    df.insert(0, 'image_path', paths)\n    df.insert(0, 'label_encoded', labels)\n    df.insert(0, 'label', [CATEGORIES[l] for l in labels])\n    \n    # Simpan\n    filename = 'efficientnet_features(non normalized).csv'\n    df.to_csv(filename, index=False)\n    \n    print(f\"âœ… Selesai! File tersimpan: {filename}\")\n    print(f\"   Dimensi Data: {df.shape}\")\n    return df\n\n# ==================== MAIN PROGRAM ====================\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"EFFICIENTNET-B3 FEATURE EXTRACTION (SIMPLE)\")\n    print(\"=\"*50)\n    \n    # 1. Input\n    image_paths, labels = load_dataset(DATA_DIR)\n    \n    if len(image_paths) > 0:\n        # 2. Proses\n        features, encoded_labels, paths = extract_features_efficientnet(\n            image_paths, labels, BATCH_SIZE\n        )\n        \n        # 3. Output\n        save_to_csv(features, encoded_labels, paths)\n        \n        print(\"\\nğŸ‰ Siap! Silakan download CSV dari tab 'Output'.\")\n    else:\n        print(\"\\nâŒ Tidak ada gambar yang bisa diproses.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T15:08:22.330271Z","iopub.execute_input":"2025-12-07T15:08:22.330498Z","iopub.status.idle":"2025-12-07T15:08:59.533303Z","shell.execute_reply.started":"2025-12-07T15:08:22.330475Z","shell.execute_reply":"2025-12-07T15:08:59.532415Z"}},"outputs":[{"name":"stdout","text":"==================================================\nEFFICIENTNET-B3 FEATURE EXTRACTION (SIMPLE)\n==================================================\nğŸ“‚ Membaca dataset dari: /kaggle/input/eye-diseases-classification/dataset\n   âœ… normal: 1074 gambar\n   âœ… cataract: 1038 gambar\n   âœ… glaucoma: 1007 gambar\n   âœ… diabetic_retinopathy: 1098 gambar\n\nâš™ï¸ Menggunakan Device: cuda\nğŸš€ Loading EfficientNet-B3 (Pretrained)...\n\nâ³ Mulai Ekstraksi Fitur (4217 gambar)...\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132/132 [00:30<00:00,  4.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ’¾ Menyimpan ke CSV...\nâœ… Selesai! File tersimpan: efficientnet_features(non normalized).csv\n   Dimensi Data: (4217, 1539)\n\nğŸ‰ Siap! Silakan download CSV dari tab 'Output'.\n","output_type":"stream"}],"execution_count":12}]}