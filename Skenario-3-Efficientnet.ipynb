{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00b882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Konfigurasi Global\n",
    "RANDOM_STATE = 42\n",
    "all_scenario_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7c22dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(scaled=False):\n",
    "    models = {}\n",
    "    models['SVM'] = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # Tuning LogReg berdasarkan status scaling\n",
    "    c_param = 0.01\n",
    "    models['Logistic Regression'] = LogisticRegression(C=c_param, max_iter=1000, random_state=RANDOM_STATE)\n",
    "    models['Decision Tree'] = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "    models['Random Forest'] = RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE)\n",
    "    models['XGBoost'] = xgb.XGBClassifier(eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_test, y_test, scenario_name, scaled_status):\n",
    "    \"\"\"\n",
    "    Fungsi training dan evaluasi standar.\n",
    "    Menambahkan hasil ke list global 'all_scenario_results'.\n",
    "    \"\"\"\n",
    "    models = get_models(scaled=scaled_status)\n",
    "    \n",
    "    print(f\"Running Skenario: {scenario_name}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        kategori = \"ENSEMBLE\" if name in ['Random Forest', 'XGBoost'] else \"SINGLE\"\n",
    "        \n",
    "        # Training\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluasi (SAMA PERSIS DENGAN KODE SEBELUMNYA)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        # Simpan ke global list\n",
    "        all_scenario_results.append({\n",
    "            'Skenario': scenario_name,\n",
    "            'Category': kategori,\n",
    "            'Model': name,\n",
    "            'Accuracy': acc,\n",
    "            'Precision': prec,\n",
    "            'Recall': rec,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "        print(f\"{name:<20} | F1: {f1:.2%}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd79ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Skenario: Non-Norm + No Scaler\n",
      "------------------------------------------------------------\n",
      "SVM                  | F1: 89.53%\n",
      "Logistic Regression  | F1: 84.70%\n",
      "Decision Tree        | F1: 73.76%\n",
      "Random Forest        | F1: 86.85%\n",
      "XGBoost              | F1: 89.70%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI A =================\n",
    "# Input: Non-Normalized CSV\n",
    "# Proses: Tanpa Scaler\n",
    "train_path = 'Dataset-Split/train_efficientnet_features(non normalized).csv'\n",
    "test_path = 'Dataset-Split/test_efficientnet_features(non normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Jalankan Evaluasi (scaled_status=False)\n",
    "    evaluate_models(X_train, y_train, X_test, y_test, \n",
    "                   scenario_name=\"Non-Norm + No Scaler\", \n",
    "                   scaled_status=False)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc7142ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Skenario: Non-Norm + With Scaler\n",
      "------------------------------------------------------------\n",
      "SVM                  | F1: 90.57%\n",
      "Logistic Regression  | F1: 91.10%\n",
      "Decision Tree        | F1: 73.76%\n",
      "Random Forest        | F1: 86.85%\n",
      "XGBoost              | F1: 89.70%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI B =================\n",
    "# Input: Non-Normalized CSV\n",
    "# Proses: Dengan StandardScaler\n",
    "train_path = 'Dataset-Split/train_efficientnet_features(non normalized).csv'\n",
    "test_path = 'Dataset-Split/test_efficientnet_features(non normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Apply Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Jalankan Evaluasi (scaled_status=True)\n",
    "    evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test, \n",
    "                   scenario_name=\"Non-Norm + With Scaler\", \n",
    "                   scaled_status=True)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79918380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Skenario: Normalized + No Scaler\n",
      "------------------------------------------------------------\n",
      "SVM                  | F1: 89.81%\n",
      "Logistic Regression  | F1: 86.99%\n",
      "Decision Tree        | F1: 76.81%\n",
      "Random Forest        | F1: 86.86%\n",
      "XGBoost              | F1: 89.89%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI C =================\n",
    "# Input: Normalized CSV (Bawaan EfficientNet)\n",
    "# Proses: Tanpa Scaler\n",
    "train_path = 'Dataset-Split/train_efficientnet_features(normalized).csv'\n",
    "test_path = 'Dataset-Split/test_efficientnet_features(normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Jalankan Evaluasi (scaled_status=False)\n",
    "    evaluate_models(X_train, y_train, X_test, y_test, \n",
    "                   scenario_name=\"Normalized + No Scaler\", \n",
    "                   scaled_status=False)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54279af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Skenario: Normalized + With Scaler\n",
      "------------------------------------------------------------\n",
      "SVM                  | F1: 91.79%\n",
      "Logistic Regression  | F1: 91.27%\n",
      "Decision Tree        | F1: 76.81%\n",
      "Random Forest        | F1: 86.86%\n",
      "XGBoost              | F1: 89.89%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================= KOMBINASI D =================\n",
    "# Input: Normalized CSV\n",
    "# Proses: Dengan StandardScaler\n",
    "train_path = 'Dataset-Split/train_efficientnet_features(normalized).csv'\n",
    "test_path = 'Dataset-Split/test_efficientnet_features(normalized).csv'\n",
    "\n",
    "if os.path.exists(train_path):\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    \n",
    "    feat_cols = [c for c in df_train.columns if c.startswith('feature_')]\n",
    "    target_col = 'label_encoded' if 'label_encoded' in df_train.columns else df_train.columns[-1]\n",
    "    \n",
    "    X_train = df_train[feat_cols].values\n",
    "    y_train = df_train[target_col].values\n",
    "    X_test = df_test[feat_cols].values\n",
    "    y_test = df_test[target_col].values\n",
    "    \n",
    "    # Apply Scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Jalankan Evaluasi (scaled_status=True)\n",
    "    evaluate_models(X_train_scaled, y_train, X_test_scaled, y_test, \n",
    "                   scenario_name=\"Normalized + With Scaler\", \n",
    "                   scaled_status=True)\n",
    "else:\n",
    "    print(f\"File tidak ditemukan: {train_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5998decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HASIL AKHIR: PERBANDINGAN KOMBINASI PREPROCESSING (EFFICIENTNET)\n",
      "================================================================================\n",
      "                Skenario Category               Model Accuracy Precision Recall F1-Score\n",
      "Normalized + With Scaler   SINGLE                 SVM   91.82%    91.90% 91.82%   91.79%\n",
      "Normalized + With Scaler   SINGLE Logistic Regression   91.23%    91.33% 91.23%   91.27%\n",
      "  Non-Norm + With Scaler   SINGLE Logistic Regression   91.11%    91.11% 91.11%   91.10%\n",
      "  Non-Norm + With Scaler   SINGLE                 SVM   90.64%    90.67% 90.64%   90.57%\n",
      "Normalized + With Scaler ENSEMBLE             XGBoost   89.93%    89.90% 89.93%   89.89%\n",
      "  Normalized + No Scaler ENSEMBLE             XGBoost   89.93%    89.90% 89.93%   89.89%\n",
      "  Normalized + No Scaler   SINGLE                 SVM   89.81%    89.88% 89.81%   89.81%\n",
      "  Non-Norm + With Scaler ENSEMBLE             XGBoost   89.81%    89.77% 89.81%   89.70%\n",
      "    Non-Norm + No Scaler ENSEMBLE             XGBoost   89.81%    89.77% 89.81%   89.70%\n",
      "    Non-Norm + No Scaler   SINGLE                 SVM   89.57%    89.68% 89.57%   89.53%\n",
      "  Normalized + No Scaler   SINGLE Logistic Regression   86.97%    87.04% 86.97%   86.99%\n",
      "  Normalized + No Scaler ENSEMBLE       Random Forest   86.85%    87.00% 86.85%   86.86%\n",
      "Normalized + With Scaler ENSEMBLE       Random Forest   86.85%    87.00% 86.85%   86.86%\n",
      "  Non-Norm + With Scaler ENSEMBLE       Random Forest   86.97%    86.93% 86.97%   86.85%\n",
      "    Non-Norm + No Scaler ENSEMBLE       Random Forest   86.97%    86.93% 86.97%   86.85%\n",
      "    Non-Norm + No Scaler   SINGLE Logistic Regression   84.72%    84.71% 84.72%   84.70%\n",
      "  Normalized + No Scaler   SINGLE       Decision Tree   76.90%    76.91% 76.90%   76.81%\n",
      "Normalized + With Scaler   SINGLE       Decision Tree   76.90%    76.91% 76.90%   76.81%\n",
      "  Non-Norm + With Scaler   SINGLE       Decision Tree   73.93%    73.80% 73.93%   73.76%\n",
      "    Non-Norm + No Scaler   SINGLE       Decision Tree   73.93%    73.80% 73.93%   73.76%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "BEST COMBINATION: Normalized + With Scaler\n",
      "MODEL           : SVM\n",
      "F1-SCORE        : 91.79%\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ================= REKAPITULASI HASIL =================\n",
    "if all_scenario_results:\n",
    "    df_final = pd.DataFrame(all_scenario_results)\n",
    "    \n",
    "    # Urutkan berdasarkan F1-Score Tertinggi\n",
    "    df_final = df_final.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"HASIL AKHIR: PERBANDINGAN KOMBINASI PREPROCESSING (EFFICIENTNET)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Format Tampilan Persen\n",
    "    output_table = df_final.copy()\n",
    "    for col in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
    "        output_table[col] = output_table[col].map('{:.2%}'.format)\n",
    "    \n",
    "    print(output_table.to_string(index=False))\n",
    "    \n",
    "    # Best Combination Logic\n",
    "    best = df_final.iloc[0]\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"BEST COMBINATION: {best['Skenario']}\")\n",
    "    print(f\"MODEL           : {best['Model']}\")\n",
    "    print(f\"F1-SCORE        : {best['F1-Score']:.2%}\")\n",
    "    print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Belum ada hasil yang dijalankan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
